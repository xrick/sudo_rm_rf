{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relevant-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained models available:\n",
      "Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt\n",
      "improved_sudo_epoch_500\n",
      "GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt\n",
      "Improved_Sudormrf_U16_Bases512_WSJ02mix.pt\n",
      "Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt\n",
      "Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from asteroid.metrics import get_metrics\n",
    "from pprint import pprint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the pretrained models\n",
    "print(\"Pre-trained models available:\")\n",
    "for model_name in os.listdir('../../pretrained_models'):\n",
    "    print(model_name)\n",
    "    \n",
    "def normalize_tensor_wav(wav_tensor, eps=1e-8, std=None):\n",
    "    mean = wav_tensor.mean(-1, keepdim=True)\n",
    "    if std is None:\n",
    "        std = wav_tensor.std(-1, keepdim=True)\n",
    "    return (wav_tensor - mean) / (std + eps)\n",
    "    \n",
    "anechoic_model_p = '../../pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = '../../pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt'\n",
    "anechoic_model_p = '../../pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt'\n",
    "noisy_reverberant_model_p = '../../pretrained_models/Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt'\n",
    "noisy_reverberant_model_p = '../../pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt'\n",
    "\n",
    "# Load the appropriate class modules\n",
    "sys.path.append(\"../../\")\n",
    "import sudo_rm_rf.dnn.models.improved_sudormrf as improved_sudormrf\n",
    "import sudo_rm_rf.dnn.models.groupcomm_sudormrf_v2 as sudormrf_gc_v2\n",
    "import sudo_rm_rf.dnn.models.sepformer as sepformer\n",
    "from speechbrain.pretrained import SepformerSeparation as sep_former_separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "magnetic-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models for forward and backward runs on GPU\n",
    "def count_parameters(model):\n",
    "    numparams = 0\n",
    "    for f in model.parameters():\n",
    "        if f.requires_grad:\n",
    "            numparams += f.numel()\n",
    "    print('Trainable Parameters (millions): {}'.format(\n",
    "        round(numparams / 10**6, 3)))\n",
    "    return numparams\n",
    "\n",
    "def backward_pass(model, input_samples=32000,\n",
    "                  repeats=1, bs=4, n_sources=2, mode='cpu', is_sudo_model=True):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    def l1_wrapper(x, y):\n",
    "        return torch.mean(torch.abs(x - y))\n",
    "    tr_loss = l1_wrapper\n",
    "    \n",
    "    if is_sudo_model:\n",
    "        mixture = torch.rand([bs, 1, input_samples])\n",
    "        clean_wavs = torch.rand([bs, n_sources, input_samples])\n",
    "    else:\n",
    "        mixture = torch.rand([bs, input_samples])\n",
    "        clean_wavs = torch.rand([bs, input_samples, n_sources])\n",
    "    \n",
    "    if mode == 'gpu':\n",
    "        model = model.cuda()\n",
    "        mixture = mixture.cuda()\n",
    "        clean_wavs = clean_wavs.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    for f in model.parameters():\n",
    "        f.requires_grad = True\n",
    "    \n",
    "    count_parameters(model)\n",
    "\n",
    "    total_time = 0.\n",
    "    for i in range(repeats):\n",
    "        now = time.time()\n",
    "        opt.zero_grad()\n",
    "        est_sources = model(mixture)\n",
    "        l = tr_loss(est_sources, clean_wavs)\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        total_time += time.time() - now\n",
    "    avg_time = (total_time) / repeats\n",
    "    peak_cuda_mem = torch.cuda.max_memory_allocated() / 10 ** 9\n",
    "    print(f'Elapsed Time Backward DEV: {mode} BS: {bs}, {avg_time} sec, Peak GPU usage {peak_cuda_mem} GB')\n",
    "\n",
    "    \n",
    "    if mode == 'gpu':\n",
    "        del model, opt, mixture, clean_wavs\n",
    "    \n",
    "    return avg_time, peak_cuda_mem\n",
    "    \n",
    "    \n",
    "def forward_pass(model, input_samples=32000,\n",
    "                  repeats=1, bs=4, n_sources=2, mode='cpu', is_sudo_model=True):    \n",
    "    if is_sudo_model:\n",
    "        mixture = torch.rand([bs, 1, input_samples])\n",
    "    else:\n",
    "        mixture = torch.rand([bs, input_samples])\n",
    "    \n",
    "    if mode == 'gpu':\n",
    "        model = model.cuda()\n",
    "        mixture = mixture.cuda()\n",
    "\n",
    "    total_time = 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(repeats):\n",
    "            now = time.time()\n",
    "            est_sources = model(mixture)\n",
    "            total_time += time.time() - now\n",
    "        avg_time = (total_time) / repeats\n",
    "    peak_cuda_mem = torch.cuda.max_memory_allocated() / 10 ** 9\n",
    "    print(f'Elapsed Time Forward DEV: {mode} BS: {bs}, {avg_time} sec, Peak GPU usage {peak_cuda_mem} GB')\n",
    "    \n",
    "    if mode == 'gpu':\n",
    "        del model, mixture\n",
    "    \n",
    "    return avg_time, peak_cuda_mem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stable-nepal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "Evaluating model: Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt\n",
      "Elapsed Time Forward DEV: cpu BS: 1, 3.1384077787399294 sec, Peak GPU usage 0.0 GB\n",
      "Elapsed Time Forward DEV: gpu BS: 1, 0.09933750629425049 sec, Peak GPU usage 0.229693952 GB\n",
      "Trainable Parameters (millions): 23.239\n",
      "Elapsed Time Backward DEV: gpu BS: 1, 0.4485529184341431 sec, Peak GPU usage 5.262242304 GB\n"
     ]
    }
   ],
   "source": [
    "models_to_eval = [\n",
    "#     {\n",
    "#         'model_path': '../../pretrained_models/GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt',\n",
    "#         'is_sudo_model': True,\n",
    "#         'bs_list': [1, 2, 4, 6]\n",
    "#     },\n",
    "#     {\n",
    "#         'model_path': '../../pretrained_models/Improved_Sudormrf_U16_Bases512_WSJ02mix.pt',\n",
    "#         'is_sudo_model': True,\n",
    "#         'bs_list': [1, 2, 4]\n",
    "#     },\n",
    "    {\n",
    "        'model_path': '../../pretrained_models/Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt',\n",
    "        'is_sudo_model': True,\n",
    "        'bs_list': [1]\n",
    "    },\n",
    "#     {\n",
    "#         'model_path': '../../pretrained_models/Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt',\n",
    "#         'is_sudo_model': True,\n",
    "#         'bs_list': [1, 2, 4]\n",
    "#     },\n",
    "#     {\n",
    "#         'model_path': '../../pretrained_models/Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt',\n",
    "#         'is_sudo_model': True,\n",
    "#         'bs_list': [1]\n",
    "#     },\n",
    "#     {\n",
    "#         'model_path': None,\n",
    "#         'is_sudo_model': False,\n",
    "#         'bs_list': [1]\n",
    "#     }\n",
    "]\n",
    "\n",
    "def get_model(model_info, is_gpu=False):\n",
    "    if model_info['model_path'] is None:\n",
    "        if is_gpu:\n",
    "            model = sep_former_separator.from_hparams(source=\"speechbrain/sepformer-wsj02mix\", \n",
    "                                           savedir='pretrained_models/sepformer-wsj02mix',\n",
    "                                           run_opts={\"device\":\"cuda\"})\n",
    "        else:\n",
    "            model = sep_former_separator.from_hparams(source=\"speechbrain/sepformer-wsj02mix\", \n",
    "                                           savedir='pretrained_models/sepformer-wsj02mix')\n",
    "        \n",
    "        model_name = \"Sepformer\"\n",
    "    else:\n",
    "        model = torch.load(model_info['model_path'])\n",
    "        model_name = model_info['model_path'].split('/')[-1]\n",
    "    return model, model_name\n",
    "\n",
    "\n",
    "for model_info in models_to_eval:\n",
    "    model, model_name = get_model(model_info, is_gpu=False)\n",
    "    model.train()\n",
    "    print(\"======================\")\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    \n",
    "    for bs in model_info['bs_list']:\n",
    "        \n",
    "        model, model_name = get_model(model_info)\n",
    "        avg_time, cuda_max_mem = forward_pass(model, input_samples=32000,\n",
    "                  repeats=10, bs=bs, n_sources=2, mode='cpu', is_sudo_model=model_info['is_sudo_model'])\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        model, model_name = get_model(model_info, is_gpu=True)\n",
    "        avg_time, cuda_max_mem = forward_pass(model, input_samples=32000,\n",
    "                  repeats=20, bs=bs, n_sources=2, mode='gpu', is_sudo_model=model_info['is_sudo_model'])\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        model, model_name = get_model(model_info, is_gpu=True)\n",
    "        avg_time, cuda_max_mem = backward_pass(model, input_samples=32000,\n",
    "                  repeats=20, bs=bs, n_sources=2, mode='gpu', is_sudo_model=model_info['is_sudo_model'])\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "complex-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "computation_metrics_results = \"\"\"\n",
    "======================\n",
    "Evaluating model: GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt\n",
    "Elapsed Time Forward DEV: cpu BS: 1, 0.6553239345550537 sec, Peak GPU usage 0.0 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 1, 0.02278091907501221 sec, Peak GPU usage 0.061922816 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 2, 1.4939395904541015 sec, Peak GPU usage 0.061922816 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 2, 0.02694549560546875 sec, Peak GPU usage 0.121698816 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 4, 3.5484800577163695 sec, Peak GPU usage 0.121698816 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 4, 0.05067609548568726 sec, Peak GPU usage 0.246493696 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 6, 6.017881846427917 sec, Peak GPU usage 0.246493696 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 6, 0.07618927955627441 sec, Peak GPU usage 0.362899968 GB\n",
    "\n",
    "Trainable Parameters (millions): 0.507\n",
    "Elapsed Time Backward DEV: gpu BS: 1, 0.12531145811080932 sec, Peak GPU usage 1.451049472 GB\n",
    "Trainable Parameters (millions): 0.507\n",
    "Elapsed Time Backward DEV: gpu BS: 2, 0.14525175094604492 sec, Peak GPU usage 2.905540096 GB\n",
    "Trainable Parameters (millions): 0.507\n",
    "Elapsed Time Backward DEV: gpu BS: 4, 0.2209705352783203 sec, Peak GPU usage 5.941104128 GB\n",
    "Trainable Parameters (millions): 0.507\n",
    "Elapsed Time Backward DEV: gpu BS: 6, 0.3077015161514282 sec, Peak GPU usage 8.738743808 GB\n",
    "\n",
    "======================\n",
    "Evaluating model: Improved_Sudormrf_U16_Bases512_WSJ02mix.pt\n",
    "Elapsed Time Forward DEV: cpu BS: 1, 1.0378467798233033 sec, Peak GPU usage 0.0 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 1, 0.03812741041183472 sec, Peak GPU usage 0.0765824 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 2, 2.2890385150909425 sec, Peak GPU usage 0.0765824 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 2, 0.04016602039337158 sec, Peak GPU usage 0.1330816 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 4, 4.936136507987976 sec, Peak GPU usage 0.1330816 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 4, 0.07500633001327514 sec, Peak GPU usage 0.254468608 GB\n",
    "\n",
    "Trainable Parameters (millions): 5.016\n",
    "Elapsed Time Backward DEV: gpu BS: 1, 0.18350332975387573 sec, Peak GPU usage 2.099536384 GB\n",
    "Trainable Parameters (millions): 5.016\n",
    "Elapsed Time Backward DEV: gpu BS: 2, 0.21717438697814942 sec, Peak GPU usage 4.127073792 GB\n",
    "Trainable Parameters (millions): 5.016\n",
    "Elapsed Time Backward DEV: gpu BS: 4, 0.34041128158569334 sec, Peak GPU usage 8.43066112 GB\n",
    "\n",
    "\n",
    "======================\n",
    "Evaluating model: Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt\n",
    "Elapsed Time Forward DEV: cpu BS: 1, 1.2158073425292968 sec, Peak GPU usage 0.0 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 1, 0.03812267780303955 sec, Peak GPU usage 0.162170368 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 2, 2.798716926574707 sec, Peak GPU usage 0.162170368 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 2, 0.043878686428070066 sec, Peak GPU usage 0.288383488 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 4, 5.887118864059448 sec, Peak GPU usage 0.288383488 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 4, 0.0821913480758667 sec, Peak GPU usage 0.551295488 GB\n",
    "\n",
    "Trainable Parameters (millions): 6.363\n",
    "Elapsed Time Backward DEV: gpu BS: 1, 0.18807061910629272 sec, Peak GPU usage 2.443395584 GB\n",
    "Trainable Parameters (millions): 6.363\n",
    "Elapsed Time Backward DEV: gpu BS: 2, 0.21935930252075195 sec, Peak GPU usage 4.771350016 GB\n",
    "Trainable Parameters (millions): 6.363\n",
    "Elapsed Time Backward DEV: gpu BS: 4, 0.35598028898239137 sec, Peak GPU usage 9.697005056 GB\n",
    "\n",
    "======================\n",
    "Evaluating model: Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt\n",
    "Elapsed Time Forward DEV: cpu BS: 1, 3.144366216659546 sec, Peak GPU usage 0.0 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 1, 0.1018365502357483 sec, Peak GPU usage 0.229693952 GB\n",
    "Trainable Parameters (millions): 23.239\n",
    "Elapsed Time Backward DEV: gpu BS: 1, 0.46427216529846194 sec, Peak GPU usage 5.262242304 GB\n",
    "\n",
    "======================\n",
    "Evaluating model: Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt\n",
    "Elapsed Time Forward DEV: cpu BS: 1, 3.7126335859298707 sec, Peak GPU usage 0.0 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 1, 0.09852558374404907 sec, Peak GPU usage 0.368998912 GB\n",
    "Elapsed Time Forward DEV: cpu BS: 2, 7.979483270645142 sec, Peak GPU usage 0.0 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 2, 0.11349769830703735 sec, Peak GPU usage 0.631526912 GB\n",
    "Trainable Parameters (millions): 26.608\n",
    "Elapsed Time Backward DEV: gpu BS: 1, 0.45119341611862185 sec, Peak GPU usage 5.727252992 GB\n",
    "\n",
    "======================\n",
    "Evaluating model: Sepformer\n",
    "Elapsed Time Forward DEV: cpu BS: 1, 9.050826048851013 sec, Peak GPU usage 0.0 GB\n",
    "Elapsed Time Forward DEV: gpu BS: 1, 0.09447981119155884 sec, Peak GPU usage 0.392123904 GB\n",
    "Trainable Parameters (millions): 25.679\n",
    "Elapsed Time Backward DEV: gpu BS: 1, 0.28271385431289675 sec, Peak GPU usage 8.156322816 GB\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "remarkable-textbook",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      " GroupCom_Sudormrf_U8_Bases512_WSJ02mix.pt\n",
      "{'Params': '0.51',\n",
      " 'exsec cpu for': '1.5 <br> 0.3',\n",
      " 'exsec gpu back': '31.9 <br> 18.1',\n",
      " 'exsec gpu for': '43.9 <br> 78.9',\n",
      " 'mem gpu back': '1.45 <br> 5.94',\n",
      " 'mem gpu for': '0.06 <br> 0.25',\n",
      " 'time cpu for': '0.66 <br> 3.55',\n",
      " 'time gpu back': '0.13 <br> 0.22',\n",
      " 'time gpu for': '0.02 <br> 0.05'}\n",
      "1.5 <br> 0.3 | 43.9 <br> 78.9 | 0.06 <br> 0.25 | 31.9 <br> 18.1 | 1.45 <br> 5.94 | 0.51\n",
      "=========\n",
      " Improved_Sudormrf_U16_Bases512_WSJ02mix.pt\n",
      "{'Params': '5.02',\n",
      " 'exsec cpu for': '3.9 <br> 0.2',\n",
      " 'exsec gpu back': '21.8 <br> 11.8',\n",
      " 'exsec gpu for': '26.2 <br> 53.3',\n",
      " 'mem gpu back': '2.1 <br> 8.43',\n",
      " 'mem gpu for': '0.08 <br> 0.25',\n",
      " 'time cpu for': '1.04 <br> 4.94',\n",
      " 'time gpu back': '0.18 <br> 0.34',\n",
      " 'time gpu for': '0.04 <br> 0.08'}\n",
      "3.9 <br> 0.2 | 26.2 <br> 53.3 | 0.08 <br> 0.25 | 21.8 <br> 11.8 | 2.1 <br> 8.43 | 5.02\n",
      "=========\n",
      " Improved_Sudormrf_U16_Bases2048_WHAMRexclmark.pt\n",
      "{'Params': '6.36',\n",
      " 'exsec cpu for': '3.3 <br> 0.2',\n",
      " 'exsec gpu back': '21.3 <br> 11.2',\n",
      " 'exsec gpu for': '26.2 <br> 48.7',\n",
      " 'mem gpu back': '2.44 <br> 9.7',\n",
      " 'mem gpu for': '0.16 <br> 0.55',\n",
      " 'time cpu for': '1.22 <br> 5.89',\n",
      " 'time gpu back': '0.19 <br> 0.36',\n",
      " 'time gpu for': '0.04 <br> 0.08'}\n",
      "3.3 <br> 0.2 | 26.2 <br> 48.7 | 0.16 <br> 0.55 | 21.3 <br> 11.2 | 2.44 <br> 9.7 | 6.36\n",
      "=========\n",
      " Improved_Sudormrf_U36_Bases2048_WSJ02mix.pt\n",
      "{'Params': '23.24',\n",
      " 'exsec cpu for': '1.3',\n",
      " 'exsec gpu back': '2.2',\n",
      " 'exsec gpu for': '9.8',\n",
      " 'mem gpu back': '5.26',\n",
      " 'mem gpu for': '0.23',\n",
      " 'time cpu for': '3.14',\n",
      " 'time gpu back': '0.46',\n",
      " 'time gpu for': '0.1'}\n",
      "1.3 | 9.8 | 0.23 | 2.2 | 5.26 | 23.24\n",
      "=========\n",
      " Improved_Sudormrf_U36_Bases4096_WHAMRexclmark.pt\n",
      "{'Params': '26.61',\n",
      " 'exsec cpu for': '0.3',\n",
      " 'exsec gpu back': '2.2',\n",
      " 'exsec gpu for': '10.1',\n",
      " 'mem gpu back': '5.73',\n",
      " 'mem gpu for': '0.37',\n",
      " 'time cpu for': '3.71',\n",
      " 'time gpu back': '0.45',\n",
      " 'time gpu for': '0.1'}\n",
      "0.3 | 10.1 | 0.37 | 2.2 | 5.73 | 26.61\n",
      "=========\n",
      " Sepformer\n",
      "{'Params': '25.68',\n",
      " 'exsec cpu for': '0.1',\n",
      " 'exsec gpu back': '3.5',\n",
      " 'exsec gpu for': '10.6',\n",
      " 'mem gpu back': '8.16',\n",
      " 'mem gpu for': '0.39',\n",
      " 'time cpu for': '9.05',\n",
      " 'time gpu back': '0.28',\n",
      " 'time gpu for': '0.09'}\n",
      "0.1 | 10.6 | 0.39 | 3.5 | 8.16 | 25.68\n"
     ]
    }
   ],
   "source": [
    "# PArse the results\n",
    "from pprint import pprint\n",
    "\n",
    "comp_res_dic = {}\n",
    "for model_res in computation_metrics_results.split(\"======================\"):\n",
    "    this_model = None\n",
    "    for l in model_res.split(\"\\n\"):\n",
    "        if l.startswith(\"Evaluating\"):\n",
    "            comp_res_dic[l.split(\" \")[-1]] = {}\n",
    "            this_model = l.split(\" \")[-1]\n",
    "            continue\n",
    "        if l.startswith(\"Trainable\"):\n",
    "            comp_res_dic[this_model][\"Params\"] = str(round(float(l.split(\" \")[-1]), 2))\n",
    "        else:\n",
    "            if \"BS: 2\" in l or \"BS: 6\" in l:\n",
    "                continue\n",
    "            \n",
    "            info = l.split(\" \")\n",
    "            if \"Backward\" in l:\n",
    "                if \"mem gpu back\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"mem gpu back\"] = str(round(float(info[-2]), 2))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"mem gpu back\"] += f\" <br> {round(float(info[-2]), 2)}\"\n",
    "                if \"time gpu back\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"time gpu back\"] = str(round(float(info[-7]), 2))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"time gpu back\"] += f\" <br> {round(float(info[-7]), 2)}\"\n",
    "                if \"exsec gpu back\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"exsec gpu back\"] = str(round(this_bs / float(info[-7]), 1))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"exsec gpu back\"] += f\" <br> {round(this_bs / float(info[-7]), 1)}\"\n",
    "            elif \"Forward DEV: gpu\" in l:\n",
    "                this_bs = int(info[-8][0])\n",
    "                if \"mem gpu for\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"mem gpu for\"] = str(round(float(info[-2]), 2))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"mem gpu for\"] += f\" <br> {round(float(info[-2]), 2)}\"\n",
    "                if \"time gpu for\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"time gpu for\"] = str(round(float(info[-7]), 2))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"time gpu for\"] += f\" <br> {round(float(info[-7]), 2)}\"\n",
    "                if \"exsec gpu for\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"exsec gpu for\"] = str(round(this_bs / float(info[-7]), 1))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"exsec gpu for\"] += f\" <br> {round(this_bs / float(info[-7]), 1)}\"\n",
    "\n",
    "            elif \"Forward DEV: cpu\" in l:\n",
    "                if \"time cpu for\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"time cpu for\"] = str(round(float(info[-7]), 2))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"time cpu for\"] += f\" <br> {round(float(info[-7]), 2)}\"\n",
    "                if \"exsec cpu for\" not in comp_res_dic[this_model]:\n",
    "                    comp_res_dic[this_model][\"exsec cpu for\"] = str(round(this_bs / float(info[-7]), 1))\n",
    "                else:\n",
    "                    comp_res_dic[this_model][\"exsec cpu for\"] += f\" <br> {round(this_bs / float(info[-7]), 1)}\"\n",
    "            print\n",
    "for m in comp_res_dic:\n",
    "    print(\"=========\\n\", m)\n",
    "    pprint(comp_res_dic[m])\n",
    "    acc = []\n",
    "    for metric in ['exsec cpu for', \n",
    "                   'exsec gpu for', 'mem gpu for', \n",
    "                   'exsec gpu back', 'mem gpu back', 'Params']:\n",
    "        acc.append(comp_res_dic[m][metric])\n",
    "\n",
    "#     print(acc)\n",
    "    print(\" | \".join(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-malawi",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
